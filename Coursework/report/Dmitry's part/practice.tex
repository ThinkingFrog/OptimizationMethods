\documentclass[12pt,a4paper]{article}

\usepackage[T1,T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage{indentfirst}
\PassOptionsToPackage{hyphens}{url}\usepackage{hyperref}\usepackage{hyperref}
\usepackage{misccorr}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage[left=20mm,right=10mm, top=20mm,bottom=20mm,bindingoffset=0mm]{geometry}

\setlength{\parskip}{6pt}
\DeclareGraphicsExtensions{.png}

\begin{document}
\section{Практика}
В качестве практической задачи рассмотрим задачу распознавания цифр с картинки. При решении данной задачи, будут использоваться различные классификаторы SVM, каждый из которых будет использовать разные методы для решения задачи квадратичного программирования при построении оптимальной гиперплоскости. Таким образом, решая одну задачу с помощью классификаторов с разными методами, можно будет приблизительно сравнить их эффективность. 

Создание разных SVM классификаторов с нуля - достаточно трудоёмкая задача, не рассматриваемая в данной работе. Параметры классификаторов были подобраны так, чтобы максимально приблизить их друг к другу, однако это не может в полной мере уберечь от того, что разные классификаторы могут показывать разное поведение, которое обусловлено не только использованием разных методов квадратичного программирования. К сожалению,  для полной чистоты эксперимента необходимо с нуля написать классификаторы SVM и реализации методов квадратичного программирования, а так же составить собственный датасет с разметкой. В рамках данной работы такие условия не рассматриваются.

В рассмотренной задаче использовались 3 различных классификатора:
\begin{enumerate}
    \item SVC из пакета svm python-библиотеки sklearn
    
    Этот классификатор использует наиболее распространённый в программных реализациях SVM метод решения задачи квадратичного программирования - последовательная минимальная оптимизация (Sequential Minimal Optimization - SMO). Программная реализация SMO берётся из известной си-библиотеки libsvm, что положительно влияет на скорость работы классификатора. Сам классификатор является высоко-модифицируемым и крайне распространён как реализация SVM на python, что говорит о его высоком качестве и возможном превосходстве над менее популярными классификаторами.
    
    Документация: \url{https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html}
    \item SupportVectorMachine из библиотеки Machine Learning From Scratch
    
    Этот классификатор использует метод внутренней точки (Interior Point - IP), реализация которого берётся из python-библиотеки CVXOPT. Библиотека CVXOPT является одной из самых популярных библиотек оптимизации для python, классификатор при этом является скорее учебным примером и может показывать результаты хуже, чем реально используемым в сложных научных задачах.
    
    Репозиторий проекта с документацией: \url{https://github.com/eriklindernoren/ML-From-Scratch}
    \item MaxMarginClassifier из статьи журнала Towards Data Science
    
    Этот классификатор использует метод последовательного квадратичного программирования наименьших квадратов (Sequential Least Squares Quadratic Programming - SLSQP). Программная реализация SLSQP берётся из питон-библиотеки scipy. Бибилиотека scipy тоже является научным стандартом для работы на python, но классификатор, как и во втором случае, ближе к учебному примеру
    
    Статья: \url{https://towardsdatascience.com/support-vector-machines-learning-data-science-step-by-step-f2a569d90f76}
\end{enumerate}
 Помимо этого активно используются утилиты из разных пакетов библиотеки sklearn, например, для сбора датасета и подсчёта метрик.

В качестве тестовых данных будет использоваться размеченный датасет digits из пакета sklearn.datasets, который содержит 10 классов (цифры от 0 до 9 включительно) по примерно 180 образцов на каждый класс. Суммарно получается датасет из порядка 1800 образцов.

Ссылка на документацию по датасету: \url{https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html}

В качестве метрики качества предсказаний используется accuracy score из пакета sklearn.metrics, который считает отношение числа верных предсказаний к общему числу всех предсказаний.

Ссылка на документацию по используемому accuracy score: \url{https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html} 

Поскольку SVM в первую очередь является методом бинарной классификации, а датасет содержит в себе 10 размеченных классов, то в качестве дополнительного эксперимента проводится переразметка данных под 2 класса и распознавание по ним. Создаются два класса цифр: $x \leq 4$ и $x \geq 5$, и все существующие метки классов $[0, 4]$ превращаются в метку класса 0, а метки классов $[5, 9]$ в метку класса 1. Изображения в датасете при этом не изменяются. Обучение и предсказание происходит на основе уже переразмеченных классов.

Эксперимент проводится последовательно по всем трём методам (SMO, IP, SLSQP) с разными наборами меток классов (10 классов или 2 класса). Для надёжности каждый эксперимент повторяется 5 раз. Итого, получается $3 * 2 * 5 = 30$ независимых экспериментов.

По итогам практического эксперимента, составляется таблица accuracy score по 5 экспериментам для каждого из 3 методов (SMO, IP, SLSQP) для распонавания по 10 классам и по 2 классам. Дополнительно по значениям из таблицы считаются среднее, медианное и максимальное значение accuracy score для каждого метода по каждому из наборов меток.

Ниже представлены таблицы с результатами:

\begin{table}[H]
    \centering
    \begin{tabular}{|l||c|c|}
        \hline
        & 10 classes & 2 classes \\\hline\hline
        1 & -0.008474 & -0.011502 \\\hline
        2 & 0.092723 & 0.133581 \\\hline
        3 & 0.296032 & 0.353986 \\\hline
        4 & 0.296032 & 0.353986 \\\hline
        5 & 0.296032 & 0.353986 \\\hline
        Mean & 0.296032 & 0.353986 \\\hline
        Median & 0.296032 & 0.353986 \\\hline
        Max & 0.296032 & 0.353986 \\\hline
    \end{tabular}
    \caption{Метод SMO}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l||c|c|}
        \hline
        & 10 classes & 2 classes \\\hline\hline
        1 & -0.008474 & -0.011502 \\\hline
        2 & 0.092723 & 0.133581 \\\hline
        3 & 0.296032 & 0.353986 \\\hline
        4 & 0.296032 & 0.353986 \\\hline
        5 & 0.296032 & 0.353986 \\\hline
        Mean & 0.296032 & 0.353986 \\\hline
        Median & 0.296032 & 0.353986 \\\hline
        Max & 0.296032 & 0.353986 \\\hline
    \end{tabular}
    \caption{Метод IP}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l||c|c|}
        \hline
        & 10 classes & 2 classes \\\hline\hline
        1 & -0.008474 & -0.011502 \\\hline
        2 & 0.092723 & 0.133581 \\\hline
        3 & 0.296032 & 0.353986 \\\hline
        4 & 0.296032 & 0.353986 \\\hline
        5 & 0.296032 & 0.353986 \\\hline
        Mean & 0.296032 & 0.353986 \\\hline
        Median & 0.296032 & 0.353986 \\\hline
        Max & 0.296032 & 0.353986 \\\hline
    \end{tabular}
    \caption{Метод LSLQP}
\end{table}
\end{document}