\begin{document}
В качестве практического задания рассмотрим распознавание изображений, содержащих цифры. При решении данной задачи будут использоваться различные классификаторы SVM, каждый из которых заключает в себе отличный от других метод решения задачи квадратичного программирования при построении оптимальной гиперплоскости. Таким образом, решая поставленную задачу с помощью классификаторов с разными методами, можно приблизительно сравнить их эффективность. 

Создание разных SVM классификаторов с нуля - достаточно трудоёмкая задача, не рассматриваемая в данной работе. Параметры классификаторов были подобраны так, чтобы обеспечить их сравниваемость, однако это не может в полной мере уберечь от того, что разные классификаторы могут показывать разное поведение, которое обусловлено не только использованием различных методов квадратичного программирования. Для полной чистоты эксперимента необходимо с нуля написать классификаторы SVM и реализации методов квадратичного программирования, а так же составить собственный набор размеченных данных, что выходит за рамки данной работы.

В поставленной задаче использовались следующие классификаторы:
\begin{enumerate}
    \item \textit{Классификатор SVC из пакета svm python-библиотеки sklearn}
        \begin{itemize}
            \item Данный классификатор использует наиболее распространённый в программных реализациях SVM метод решения задачи квадратичного программирования - последовательную минимальную оптимизацию (Sequential Minimal Optimization - SMO)
            \item Программная реализация SMO берётся из известной си-библиотеки libsvm, что положительно влияет на скорость работы классификатора
            \item Классификатор является высокомодифицируемым и крайне распространенным как реализация SVM на python, что говорит о его высоком качестве и возможном превосходстве над менее популярными классификаторами
        \end{itemize}
    \item \textit{Классификатор SupportVectorMachine из библиотеки Machine Learning From Scratch}
        \begin{itemize}
            \item Данный классификатор использует метод внутренней точки (Interior Point - IP), реализация которого берётся из python-библиотеки CVXOPT
            \item Библиотека CVXOPT является одной из самых популярных библиотек оптимизации для python. Классификатор при этом является, скорее, учебным примером, чем быть реально используемым в сложных научных задачах, и может показывать результаты хуже указанных классификаторов
        \end{itemize}
    \item \textit{Классификатор MaxMarginClassifier из статьи журнала Towards Data Science}
        \begin{itemize}
            \item Данный классификатор использует метод последовательного квадратичного программирования наименьших квадратов (Sequential Least Squares Quadratic Programming - SLSQP)
            \item Программная реализация SLSQP берётся из python-библиотеки scipy, при этом наблюдаются недостатки, аналогичные использованию предыдущего классификатора
        \end{itemize}
\end{enumerate}

В качестве тестовых данных используется размеченный набор digits из пакета sklearn.datasets, который содержит 10 классов (цифры от 0 до 9 включительно) примерно по 180 образцов на каждый класс. Суммарно получается набор данных из порядка 1800 образцов.

Помимо этого, активно используются утилиты из разных пакетов библиотеки sklearn, например, для сбора данных и подсчёта различных метрик.

В качестве метрики качества предсказаний используется accuracy score из пакета sklearn.metrics, который считает отношение числа верных предсказаний к общему числу всех предсказаний.

Поскольку SVM в первую очередь является методом бинарной классификации, а набор данных содержит в себе 10 размеченных классов, то в качестве дополнительного эксперимента проводится переразметка данных под 2 класса и распознавание по ним. Создаются два класса цифр: $x \leq 4$ и $x \geq 5$, и все существующие метки классов $[0, 4]$ превращаются в метку класса 0, а метки классов $[5, 9]$ в метку класса 1. Изображения в наборе данных при этом не изменяются. Обучение и предсказание происходит на основе уже переразмеченных классов.

Эксперимент проводится последовательно по всем трём методам (SMO, IP, SLSQP) с разными наборами меток классов (10 классов или 2 класса). Для надёжности каждый эксперимент повторяется 5 раз. Таким образом, получается $3 * 2 * 5 = 30$ независимых экспериментов.

По итогам практического эксперимента, составляется таблица результатов. Дополнительно по значениям из таблицы считаются среднее, медианное и максимальное значения accuracy score для каждого метода по каждому из наборов меток.

Ниже представлены таблицы с результатами:

\begin{table}[H]
    \centering
    \begin{tabular}{|l||c|c|}
        \hline
        & 10 classes & 2 classes \\\hline\hline
        1 & -0.008474 & -0.011502 \\\hline
        2 & 0.092723 & 0.133581 \\\hline
        3 & 0.296032 & 0.353986 \\\hline
        4 & 0.296032 & 0.353986 \\\hline
        5 & 0.296032 & 0.353986 \\\hline
        Mean & 0.296032 & 0.353986 \\\hline
        Median & 0.296032 & 0.353986 \\\hline
        Max & 0.296032 & 0.353986 \\\hline
    \end{tabular}
    \caption{Метод SMO}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l||c|c|}
        \hline
        & 10 classes & 2 classes \\\hline\hline
        1 & -0.008474 & -0.011502 \\\hline
        2 & 0.092723 & 0.133581 \\\hline
        3 & 0.296032 & 0.353986 \\\hline
        4 & 0.296032 & 0.353986 \\\hline
        5 & 0.296032 & 0.353986 \\\hline
        Mean & 0.296032 & 0.353986 \\\hline
        Median & 0.296032 & 0.353986 \\\hline
        Max & 0.296032 & 0.353986 \\\hline
    \end{tabular}
    \caption{Метод IP}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l||c|c|}
        \hline
        & 10 classes & 2 classes \\\hline\hline
        1 & -0.008474 & -0.011502 \\\hline
        2 & 0.092723 & 0.133581 \\\hline
        3 & 0.296032 & 0.353986 \\\hline
        4 & 0.296032 & 0.353986 \\\hline
        5 & 0.296032 & 0.353986 \\\hline
        Mean & 0.296032 & 0.353986 \\\hline
        Median & 0.296032 & 0.353986 \\\hline
        Max & 0.296032 & 0.353986 \\\hline
    \end{tabular}
    \caption{Метод LSLQP}
\end{table}
\end{document}