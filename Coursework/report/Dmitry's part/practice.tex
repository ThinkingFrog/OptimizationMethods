\documentclass[12pt,a4paper]{article}
\begin{document}
В качестве практического задания рассмотрим распознавание изображений, содержащих цифры. При решении данной задачи будут использоваться различные классификаторы SVM, каждый из которых заключает в себе отличный от других метод решения задачи квадратичного программирования при построении оптимальной гиперплоскости. Таким образом, решая поставленную задачу с помощью классификаторов с разными методами, можно приблизительно сравнить их эффективность. 

Создание разных SVM классификаторов с нуля - достаточно трудоёмкая задача, не рассматриваемая в данной работе. Параметры классификаторов были подобраны так, чтобы обеспечить их сравниваемость, однако это не может в полной мере уберечь от того, что разные классификаторы могут показывать разное поведение, которое обусловлено не только использованием различных методов квадратичного программирования. Для полной чистоты эксперимента необходимо с нуля написать классификаторы SVM и реализации методов квадратичного программирования, а так же составить собственный набор размеченных данных, что выходит за рамки данной работы.

В поставленной задаче использовались следующие классификаторы:
\begin{enumerate}
    \item \textit{Классификатор SVC из пакета svm python-библиотеки sklearn}
        \begin{itemize}
            \item Данный классификатор использует наиболее распространённый в программных реализациях SVM метод решения задачи квадратичного программирования - последовательную минимальную оптимизацию (Sequential Minimal Optimization - SMO)
            \item Программная реализация SMO берётся из известной си-библиотеки libsvm, что положительно влияет на скорость работы классификатора
            \item Классификатор является высокомодифицируемым и крайне распространенным как реализация SVM на python, что говорит о его высоком качестве и возможном превосходстве над менее популярными классификаторами
        \end{itemize}
    \item \textit{Классификатор SupportVectorMachine из библиотеки Machine Learning From Scratch}
        \begin{itemize}
            \item Данный классификатор использует метод внутренней точки (Interior Point - IP), реализация которого берётся из python-библиотеки CVXOPT
            \item Библиотека CVXOPT является одной из самых популярных библиотек оптимизации для python. Классификатор при этом является, скорее, учебным примером, чем быть реально используемым в сложных научных задачах, и может показывать результаты хуже указанных классификаторов
        \end{itemize}
    \item \textit{Классификатор MaxMarginClassifier из статьи журнала Towards Data Science}
        \begin{itemize}
            \item Данный классификатор использует метод последовательного квадратичного программирования наименьших квадратов (Sequential Least Squares Quadratic Programming - SLSQP)
            \item Программная реализация SLSQP берётся из python-библиотеки scipy, при этом наблюдаются недостатки, аналогичные использованию предыдущего классификатора
        \end{itemize}
\end{enumerate}

В качестве тестовых данных используется размеченный набор digits из пакета sklearn.datasets, который содержит 10 классов (цифры от 0 до 9 включительно) примерно по 180 образцов на каждый класс. Суммарно получается набор данных из порядка 1800 образцов.

Помимо этого, активно используются утилиты из разных пакетов библиотеки sklearn, например, для сбора данных и подсчёта различных метрик.

В качестве метрики качества предсказаний используется accuracy score из пакета sklearn.metrics, который считает отношение числа верных предсказаний к общему числу всех предсказаний.

Поскольку SVM в первую очередь является методом бинарной классификации, а набор данных содержит в себе 10 размеченных классов, то в качестве дополнительного эксперимента проводится переразметка данных под 2 класса и распознавание по ним. Создаются два класса цифр: $x \leq 4$ и $x \geq 5$, и все существующие метки классов $[0, 4]$ превращаются в метку класса 0, а метки классов $[5, 9]$ в метку класса 1. Изображения в наборе данных при этом не изменяются. Обучение и предсказание происходит на основе уже переразмеченных классов.

Эксперимент проводится последовательно по всем трём методам (SMO, IP, SLSQP) с разными наборами меток классов (10 классов или 2 класса). Для надёжности каждый эксперимент повторяется 5 раз. Таким образом, получается $3 * 2 * 5 = 30$ независимых экспериментов.

По итогам практического эксперимента, составляется таблица результатов. Дополнительно по значениям из таблицы считаются среднее, медианное и максимальное значения accuracy score для каждого метода по каждому из наборов меток.

Ниже представлены таблицы с результатами:

\begin{table}[H]
    \centering
    \begin{tabular}{|l||c|c|}
        \hline
        & 10 classes & 2 classes \\\hline\hline
        1 & 0.988889 & 0.995556 \\\hline
        2 & 0.993333 & 0.995556 \\\hline
        3 & 0.991111 & 0.991111 \\\hline
        4 & 0.993333 & 1 \\\hline
        5 & 0.986667 & 0.991111 \\\hline
        Mean & 0.990667 & 0.994667 \\\hline
        Median & 0.991111 & 0.995556 \\\hline
        Max & 0.993333 & 1 \\\hline
    \end{tabular}
    \caption{Метод SMO}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l||c|c|}
        \hline
        & 10 classes & 2 classes \\\hline\hline
        1 & 0.0644444 & 0.488889 \\\hline
        2 & 0.0866667 & 0.504444 \\\hline
        3 & 0.0866667 & 0.451111 \\\hline
        4 & 0.108889 & 0.48 \\\hline
        5 & 0.1 & 0.506667 \\\hline
        Mean & 0.0893333 & 0.486222 \\\hline
        Median & 0.0866667 & 0.488889 \\\hline
        Max & 0.108889 & 0.506667 \\\hline
    \end{tabular}
    \caption{Метод IP}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l||c|c|}
        \hline
        & 10 classes & 2 classes \\\hline\hline
        1 & 0.111111 & 0.473333 \\\hline
        2 & 0.0911111 & 0.542222 \\\hline
        3 & 0 & 0.513333 \\\hline
        4 & 0.0911111 & 0.522222 \\\hline
        5 & 0.122222 & 0.482222 \\\hline
        Mean & 0.0831111 & 0.506667 \\\hline
        Median & 0.0911111 & 0.513333 \\\hline
        Max & 0.122222 & 0.542222 \\\hline
    \end{tabular}
    \caption{Метод LSLQP}
\end{table}

По результатам эксперимента видно, что лучшее качество на рассмотренной задаче показывает метод SMO с точностью близкой к 1, классификаторы на основе методов IP и LSLQP при этом показывают качество заметно ниже. Сравнивая методы IP и LSLQP, классификатор на основе второго метода показывает точность несколько лучше по всем параметрам в сравнении с методом внутренней точки.

Такое сильное различие в точности может быть обосновано тем, что классификатор на основе SMO является программным продуктом высокого качества, используемым в серьёзных научных задачах, а классификаторы, основанные на методах IP и LSLQP являются учебными примерами и не предназначены для настоящих задач.

Результаты эксперимента показывают, что метод последовательной минимальной оптимизации в решении задачи квадратичного программирования при использовании машины опорных векторов лучше всего подходит для данной задачи распознавания. На втором месте по точности среди рассматриваемых методов стоит метод последовательного квадратичного программирования наименьших квадрат, а наименее точным методом оказался метод внутренних точек.
\end{document}